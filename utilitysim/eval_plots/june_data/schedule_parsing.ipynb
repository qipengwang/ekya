{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing the scheduler data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "schedule_path = 'data_eval_multicam_allocationdata_cityscapes_histacc.json'\n",
    "hyps_path = 'hyp_map.json'\n",
    "TASK_ID = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format is:\n",
    "# {\n",
    "#    \"sched_key\":{\n",
    "#       \"task_id\":{\n",
    "#          \"time\":{\n",
    "#             \"job_id\":\"float\"\n",
    "#          }\n",
    "#       }\n",
    "#    }\n",
    "# }\n",
    "with open(schedule_path) as f:\n",
    "    data = json.load(f)\n",
    "with open(hyps_path) as f:\n",
    "    hyperparams = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['100_1_fair_dumb_True', '100_1_thief_True', '100_1_inference_only_True', '100_2_fair_dumb_True', '100_2_thief_True', '100_2_inference_only_True', '100_4_fair_dumb_True', '100_4_thief_True', '100_4_inference_only_True', '100_8_fair_dumb_True', '100_8_thief_True', '100_8_inference_only_True', '200_1_fair_dumb_True', '200_1_thief_True', '200_1_inference_only_True', '200_2_fair_dumb_True', '200_2_thief_True', '200_2_inference_only_True', '200_4_fair_dumb_True', '200_4_thief_True', '200_4_inference_only_True', '200_8_fair_dumb_True', '200_8_thief_True', '200_8_inference_only_True'])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_count = 1\n",
    "scheduler=\"thief\"\n",
    "oracle=\"True\"\n",
    "period=200\n",
    "schedule_key = \"{}_{}_{}_{}\".format(period,res_count,scheduler,oracle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'jena_0_train_3_8': 0.3333333333333333,\n",
       " 'zurich_1_train_6_17': 0.16666666666666666,\n",
       " 'cologne_2_train_2_8': 0.0,\n",
       " 'jena_0_inference': 0.16666666666666666,\n",
       " 'zurich_1_inference': 0.16666666666666666,\n",
       " 'cologne_2_inference': 0.16666666666666666}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data[schedule_key][TASK_ID]['0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = data[schedule_key].keys()\n",
    "inference_resource_weights = {}\n",
    "training_resource_weights = {}\n",
    "hyperparameters = {}\n",
    "for task_id in tasks:\n",
    "    for job_id in data[schedule_key][task_id]['0']:\n",
    "        cityname = job_id.split('_')[0]\n",
    "        camera_id = cityname\n",
    "        resource_alloc = data[schedule_key][task_id]['0'][job_id]\n",
    "        job_type = \"train\" if \"train\" in job_id else \"inference\"\n",
    "        if job_type == \"train\":\n",
    "            epochs = job_id.split('_')[-1]\n",
    "            hp_id = job_id.split('_')[-2]\n",
    "            this_hyps = hyperparams[hp_id]\n",
    "            this_hyps['epochs'] = epochs\n",
    "            training_resource_weights[camera_id] = resource_alloc\n",
    "            hyperparameters[camera_id] = this_hyps\n",
    "        elif job_type == \"inference\":\n",
    "            inference_resource_weights[camera_id] = resource_alloc\n",
    "        else:\n",
    "            raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'jena': {'num_hidden': 64,\n",
       "  'last_layer_only': True,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_name': 'resnet18',\n",
       "  'batch_size': 64,\n",
       "  'subsample': 0.1,\n",
       "  'momentum': 0.9,\n",
       "  'epochs': '8'},\n",
       " 'zurich': {'num_hidden': 64,\n",
       "  'last_layer_only': True,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_name': 'resnet18',\n",
       "  'batch_size': 64,\n",
       "  'subsample': 1,\n",
       "  'momentum': 0.9,\n",
       "  'epochs': '8'},\n",
       " 'cologne': {'num_hidden': 64,\n",
       "  'last_layer_only': True,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_name': 'resnet18',\n",
       "  'batch_size': 64,\n",
       "  'subsample': 0.1,\n",
       "  'momentum': 0.9,\n",
       "  'epochs': '8'}}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "inference_resource_weights = {c.id: resources/len(cameras) for c in cameras}\n",
    "training_resource_weights = {c.id: resources/len(cameras) for c in cameras}\n",
    "hyperparameters = {c.id: self.default_hyperparams for c in cameras}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
